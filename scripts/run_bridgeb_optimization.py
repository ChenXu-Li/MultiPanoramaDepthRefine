#!/usr/bin/env python3
"""
BridgeB åœºæ™¯å¤šè§†è§’æ·±åº¦è”åˆä¼˜åŒ–è„šæœ¬
è¿è¡Œ Step 4: æœ€ç»ˆè”åˆä¼˜åŒ–
"""
import sys
from pathlib import Path
import numpy as np
import torch
import pycolmap
from typing import List, Optional
import time
import json
import csv

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def log_time(msg: str):
    """æ‰“å°å¸¦æ—¶é—´æˆ³çš„æ—¥å¿—"""
    print(f"[{time.strftime('%H:%M:%S')}] {msg}", flush=True)

from src.utils.config import load_config, get_data_paths
from src.utils.io import load_image, load_depth_npy, save_depth_npy
from src.deformation import DepthReparameterization
from src.solver import JointOptimizationConfig, optimize_multi_view_depth, validate_optimized_depths
from scripts.visualize_depths import visualize_depth_diff_heatmap


def load_colmap_reconstruction(colmap_dir: Path) -> pycolmap.Reconstruction:
    """åŠ è½½ COLMAP é‡å»ºç»“æœ"""
    recon = pycolmap.Reconstruction(str(colmap_dir))
    return recon


def get_camera_pose_for_pano(
    recon: pycolmap.Reconstruction,
    pano_name: str,
    camera_name: str = "pano_camera12",
) -> Optional[pycolmap.Rigid3d]:
    """
    è·å–æŒ‡å®š pano çš„ç›¸æœºä½å§¿
    
    Args:
        recon: COLMAP é‡å»ºç»“æœ
        pano_name: å…¨æ™¯å›¾åç§°
        camera_name: ç›¸æœºåç§°å­ä¸²
        
    Returns:
        cam_from_world: pycolmap.Rigid3d ç›¸æœºå˜æ¢ï¼ˆå®é™…ä¸Šæ˜¯ world_from_camï¼‰
    """
    # æŸ¥æ‰¾å¯¹åº”çš„å›¾åƒ
    for img_id, img in recon.images.items():
        # å›¾åƒåç§°æ ¼å¼: pano_camera{idx}/{pano_name}.png
        if camera_name in img.name and pano_name in img.name:
            # è·å–ç›¸æœºä½å§¿
            if hasattr(img, 'cam_from_world'):
                cam_from_world = img.cam_from_world() if callable(img.cam_from_world) else img.cam_from_world
                return cam_from_world
    
    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•é€šè¿‡ frame æŸ¥æ‰¾
    for img_id, img in recon.images.items():
        if pano_name in img.name:
            if img.frame_id in recon.frames:
                frame = recon.frames[img.frame_id]
                if frame.has_pose():
                    # ä» frame è·å– rig_from_world
                    rig_from_world = frame.rig_from_world
                    # æŸ¥æ‰¾è¯¥ frame ä¸­æŒ‡å®šç›¸æœºçš„ cam_from_rig
                    for img2_id, img2 in recon.images.items():
                        if img2.frame_id == img.frame_id and camera_name in img2.name:
                            cam_from_world = img2.cam_from_world() if callable(img2.cam_from_world) else img2.cam_from_world
                            return cam_from_world
    
    return None


def build_pano_to_frame_mapping(recon: pycolmap.Reconstruction) -> dict:
    """å»ºç«‹ pano_name åˆ° frame_id çš„æ˜ å°„"""
    pano_to_frame = {}
    for img_id, img in recon.images.items():
        if img.frame_id not in recon.frames:
            continue
        img_name = img.name
        if '/' in img_name:
            pano_name = img_name.split('/')[-1]
            pano_name = Path(pano_name).stem
            if pano_name not in pano_to_frame:
                pano_to_frame[pano_name] = img.frame_id
    return pano_to_frame


def main():
    """ä¸»å‡½æ•°"""
    start_time = time.time()
    print("=" * 80)
    print("BridgeB åœºæ™¯å¤šè§†è§’æ·±åº¦è”åˆä¼˜åŒ–")
    print("=" * 80)
    
    # åŠ è½½é…ç½®
    config_path = project_root / "configs" / "bridgeb.yaml"
    log_time(f"ğŸ“– åŠ è½½é…ç½®: {config_path}")
    config = load_config(config_path)
    log_time(f"âœ… é…ç½®åŠ è½½å®Œæˆ ({time.time() - start_time:.2f}s)")
    
    # è·å–æ•°æ®è·¯å¾„
    scene_name = config['paths']['scene_name']
    pano_names = config['paths']['pano_names']
    camera_name = config['paths']['camera_name']
    
    print(f"  åœºæ™¯: {scene_name}")
    print(f"  å…¨æ™¯å›¾æ•°é‡: {len(pano_names)}")
    print(f"  å…¨æ™¯å›¾åˆ—è¡¨: {pano_names}")
    
    # COLMAP è·¯å¾„
    colmap_root = Path(config['paths']['colmap_root'])
    colmap_dir = colmap_root / scene_name / "sparse" / "0"
    
    log_time(f"ğŸ“– è¯»å– COLMAP é‡å»º: {colmap_dir}")
    t0 = time.time()
    recon = load_colmap_reconstruction(colmap_dir)
    log_time(f"âœ… COLMAP é‡å»ºåŠ è½½å®Œæˆ ({time.time() - t0:.2f}s)")
    
    # åŠ è½½æ‰€æœ‰ pano çš„æ•°æ®
    log_time(f"ğŸ“¦ å¼€å§‹åŠ è½½æ•°æ®...")
    t0 = time.time()
    depths_dap = []
    log_depths_dap = []
    rgbs = []
    cam_poses = []
    heights = []
    widths = []
    
    for idx, pano_name in enumerate(pano_names):
        log_time(f"  å¤„ç† {pano_name} ({idx+1}/{len(pano_names)})...")
        paths = get_data_paths(config, pano_name)
        
        # åŠ è½½ RGB
        t1 = time.time()
        log_time(f"    ğŸ“· åŠ è½½ RGB...")
        rgb = load_image(paths['rgb'])
        H, W = rgb.shape[:2]
        heights.append(H)
        widths.append(W)
        rgbs.append(torch.from_numpy(rgb.astype(np.float32)))
        log_time(f"    âœ… RGB åŠ è½½å®Œæˆ ({time.time() - t1:.2f}s)")
        
        # åŠ è½½ DAP æ·±åº¦
        t1 = time.time()
        log_time(f"    ğŸ§Š åŠ è½½ DAP æ·±åº¦...")
        depth_dap = load_depth_npy(paths['depth_dap'])
        if depth_dap.shape != (H, W):
            raise ValueError(f"{pano_name}: DAP depth shape {depth_dap.shape} != RGB shape {(H, W)}")
        
        # DAP æ·±åº¦ç¼©æ”¾ï¼ˆå‡è®¾ DAP æ·±åº¦éœ€è¦ç¼©æ”¾ 100 å€ï¼‰
        dap_scale = 100.0
        depth_dap_scaled = depth_dap * dap_scale
        depths_dap.append(torch.from_numpy(depth_dap_scaled.astype(np.float32)))
        
        # log-depth
        log_depth_dap = np.log(depth_dap_scaled + 1e-8)
        log_depths_dap.append(torch.from_numpy(log_depth_dap.astype(np.float32)))
        log_time(f"    âœ… DAP æ·±åº¦åŠ è½½å®Œæˆ ({time.time() - t1:.2f}s)")
        
        # è·å–ç›¸æœºä½å§¿
        t1 = time.time()
        log_time(f"    ğŸ“ è·å–ç›¸æœºä½å§¿...")
        cam_pose = get_camera_pose_for_pano(recon, pano_name, camera_name)
        if cam_pose is None:
            raise ValueError(f"æ— æ³•æ‰¾åˆ° {pano_name} çš„ç›¸æœºä½å§¿")
        cam_poses.append(cam_pose)
        log_time(f"    âœ… ç›¸æœºä½å§¿è·å–å®Œæˆ ({time.time() - t1:.2f}s)")
    
    log_time(f"âœ… æ•°æ®åŠ è½½å®Œæˆ ({time.time() - t0:.2f}s)")
    
    # æ£€æŸ¥æ‰€æœ‰å›¾åƒå°ºå¯¸æ˜¯å¦ä¸€è‡´
    if len(set(heights)) > 1 or len(set(widths)) > 1:
        log_time(f"âš ï¸  è­¦å‘Š: å›¾åƒå°ºå¯¸ä¸ä¸€è‡´")
        log_time(f"  é«˜åº¦: {heights}")
        log_time(f"  å®½åº¦: {widths}")
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå›¾åƒçš„å°ºå¯¸
        H, W = heights[0], widths[0]
    else:
        H, W = heights[0], widths[0]
    
    log_time(f"  å›¾åƒå°ºå¯¸: {H}x{W}")
    log_time(f"  æ·±åº¦èŒƒå›´: [{np.min([d.min().item() for d in depths_dap]):.2f}, {np.max([d.max().item() for d in depths_dap]):.2f}] ç±³")
    
    # åˆ›å»ºæ·±åº¦é‡å‚æ•°åŒ–æ¨¡å—
    log_time(f"ğŸ”§ åˆ›å»ºæ·±åº¦é‡å‚æ•°åŒ–æ¨¡å—...")
    t0 = time.time()
    depth_reparam_modules = []
    for i, pano_name in enumerate(pano_names):
        t1 = time.time()
        log_time(f"  {pano_name}: åˆ›å»ºæ¨¡å—...")
        module = DepthReparameterization(
            height=H,
            width=W,
            spline_type="monotonic_cubic",
            num_knots=10,
            scale_method="spherical_harmonics",
            sh_max_degree=4,
        )
        depth_reparam_modules.append(module)
        log_time(f"  âœ… {pano_name} æ¨¡å—åˆ›å»ºå®Œæˆ ({time.time() - t1:.2f}s)")
    log_time(f"âœ… æ‰€æœ‰æ¨¡å—åˆ›å»ºå®Œæˆ ({time.time() - t0:.2f}s)")
    
    # é…ç½®ä¼˜åŒ–å™¨ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–å‚æ•°ï¼‰
    log_time(f"âš™ï¸  é…ç½®ä¼˜åŒ–å™¨...")
    t0 = time.time()
    
    # ä»é…ç½®æ–‡ä»¶è¯»å–ä¼˜åŒ–å‚æ•°
    geometry_config = config.get('geometry', {})
    regularization_config = config.get('regularization', {})
    optimization_config = config.get('optimization', {})
    
    # å‡ ä½•ä¸€è‡´æ€§æƒé‡ï¼ˆç¡®ä¿ç±»å‹æ­£ç¡®ï¼‰
    p2r_config = geometry_config.get('point_to_ray', {})
    p2r_enabled = p2r_config.get('enabled', True)  # æ£€æŸ¥æ˜¯å¦å¯ç”¨
    if not p2r_enabled:
        log_time(f"âš ï¸  è­¦å‘Š: point_to_ray å·²ç¦ç”¨ï¼Œå‡ ä½•çº¦æŸå°†ä¸ä¼šç”Ÿæ•ˆï¼")
    lambda_p2r = float(p2r_config.get('weight', 1.0)) if p2r_enabled else 0.0  # å¦‚æœç¦ç”¨åˆ™æƒé‡ä¸º0
    use_robust_p2r = bool(p2r_config.get('use_robust_loss', True))  # ç¡®ä¿è½¬æ¢ä¸ºå¸ƒå°”å€¼
    huber_delta_p2r = float(p2r_config.get('huber_delta', 0.1))  # ç¡®ä¿è½¬æ¢ä¸ºæµ®ç‚¹æ•°
    
    depth_config = geometry_config.get('depth_consistency', {})
    lambda_depth = float(depth_config.get('weight', 0.1))  # ç¡®ä¿è½¬æ¢ä¸ºæµ®ç‚¹æ•°
    
    far_config = geometry_config.get('far_field', {})
    far_threshold = float(far_config.get('far_threshold', 100.0))  # ç¡®ä¿è½¬æ¢ä¸ºæµ®ç‚¹æ•°
    
    # æ­£åˆ™åŒ–æƒé‡ï¼ˆç¡®ä¿ç±»å‹æ­£ç¡®ï¼‰
    prior_config = regularization_config.get('prior_anchor', {})
    lambda_prior = float(prior_config.get('weight', 1.0))  # ç¡®ä¿è½¬æ¢ä¸ºæµ®ç‚¹æ•°
    prior_loss_type = str(prior_config.get('loss_type', 'l2'))  # ç¡®ä¿è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    prior_huber_delta = float(prior_config.get('huber_delta', 0.1))  # ç¡®ä¿è½¬æ¢ä¸ºæµ®ç‚¹æ•°
    
    smooth_config = regularization_config.get('smoothness', {})
    lambda_smooth = float(smooth_config.get('weight', 0.01))  # ç¡®ä¿è½¬æ¢ä¸ºæµ®ç‚¹æ•°
    smooth_type = str(smooth_config.get('smooth_type', 'l2'))  # ç¡®ä¿è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    edge_aware = bool(smooth_config.get('edge_aware', False))  # ç¡®ä¿è½¬æ¢ä¸ºå¸ƒå°”å€¼
    rgb_sigma = float(smooth_config.get('rgb_sigma', 10.0))  # ç¡®ä¿è½¬æ¢ä¸ºæµ®ç‚¹æ•°
    
    scale_config = regularization_config.get('scale_constraint', {})
    lambda_scale = float(scale_config.get('weight', 0.01))  # ç¡®ä¿è½¬æ¢ä¸ºæµ®ç‚¹æ•°
    
    # ä¼˜åŒ–å™¨é…ç½®
    solver_config = optimization_config.get('solver', {})
    optimizer = solver_config.get('optimizer', 'adam')
    lr_raw = solver_config.get('lr', 1e-3)
    # å¤„ç†å­—ç¬¦ä¸²å½¢å¼çš„ç§‘å­¦è®¡æ•°æ³•ï¼ˆå¦‚ "5e-4"ï¼‰
    if isinstance(lr_raw, str):
        lr = float(lr_raw)
    else:
        lr = float(lr_raw)  # ç¡®ä¿è½¬æ¢ä¸ºæµ®ç‚¹æ•°
    
    iteration_config = optimization_config.get('iteration', {})
    max_iter = int(iteration_config.get('max_iter', 1000))  # ç¡®ä¿è½¬æ¢ä¸ºæ•´æ•°
    early_stop_threshold_raw = iteration_config.get('early_stop_threshold', 1e-6)
    # å¤„ç†å­—ç¬¦ä¸²å½¢å¼çš„ç§‘å­¦è®¡æ•°æ³•ï¼ˆå¦‚ "1e-7"ï¼‰
    if isinstance(early_stop_threshold_raw, str):
        early_stop_threshold = float(early_stop_threshold_raw)
    else:
        early_stop_threshold = float(early_stop_threshold_raw)  # ç¡®ä¿è½¬æ¢ä¸ºæµ®ç‚¹æ•°
    save_interval = int(iteration_config.get('save_interval', 100))  # ç¡®ä¿è½¬æ¢ä¸ºæ•´æ•°
    print_interval = int(iteration_config.get('print_interval', 10))  # ç¡®ä¿è½¬æ¢ä¸ºæ•´æ•°
    
    device_config = optimization_config.get('device', {})
    device = device_config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu')
    
    opt_config = JointOptimizationConfig(
        lambda_p2r=lambda_p2r,
        lambda_depth=lambda_depth,
        lambda_prior=lambda_prior,
        lambda_smooth=lambda_smooth,
        lambda_scale=lambda_scale,
        optimizer=optimizer,
        lr=lr,
        max_iter=max_iter,
        early_stop_threshold=early_stop_threshold,
        far_threshold=far_threshold,
        use_robust_p2r=use_robust_p2r,
        huber_delta_p2r=huber_delta_p2r,
        prior_loss_type=prior_loss_type,
        prior_huber_delta=prior_huber_delta,
        smooth_type=smooth_type,
        edge_aware=edge_aware,
        rgb_sigma=rgb_sigma,
        device=device,
        save_history=True,
        save_interval=save_interval,
        print_interval=print_interval,
    )
    log_time(f"âœ… ä¼˜åŒ–å™¨é…ç½®å®Œæˆ ({time.time() - t0:.2f}s)")
    
    log_time(f"  è®¾å¤‡: {opt_config.device}")
    log_time(f"  æœ€å¤§è¿­ä»£æ¬¡æ•°: {opt_config.max_iter}")
    log_time(f"  å­¦ä¹ ç‡: {opt_config.lr}")
    
    # å°†æ•°æ®ç§»åˆ°è®¾å¤‡
    log_time(f"ğŸ“± å°†æ•°æ®ç§»åˆ°è®¾å¤‡: {opt_config.device}")
    t0 = time.time()
    device = torch.device(opt_config.device)
    
    log_time(f"  ç§»åŠ¨ log_depth_daps...")
    log_depths_dap = [d.to(device) for d in log_depths_dap]
    log_time(f"  ç§»åŠ¨ depths_dap...")
    depths_dap = [d.to(device) for d in depths_dap]
    log_time(f"  ç§»åŠ¨ rgbs...")
    rgbs = [r.to(device) for r in rgbs]
    log_time(f"  ç§»åŠ¨æ·±åº¦é‡å‚æ•°åŒ–æ¨¡å—...")
    for i, module in enumerate(depth_reparam_modules):
        t1 = time.time()
        module.to(device)
        log_time(f"    æ¨¡å— {i} å·²ç§»åŠ¨åˆ° {device} ({time.time() - t1:.2f}s)")
    
    log_time(f"âœ… æ•°æ®ç§»åŠ¨å®Œæˆ ({time.time() - t0:.2f}s)")
    
    # æ£€æŸ¥å†…å­˜ä½¿ç”¨
    if torch.cuda.is_available() and opt_config.device == "cuda":
        log_time(f"  GPU å†…å­˜ä½¿ç”¨: {torch.cuda.memory_allocated() / 1024**3:.2f} GB / {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB")
    
    # è¿è¡Œä¼˜åŒ–
    print(f"\nğŸš€ å¼€å§‹è”åˆä¼˜åŒ–...")
    output_dir = project_root / "intermediate" / "bridgeb_optimization"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # æ¸…ç†å†…å­˜
    import gc
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    try:
        depths_opt, report = optimize_multi_view_depth(
            depth_reparam_modules=depth_reparam_modules,
            log_depth_daps=log_depths_dap,
            depth_daps=depths_dap,
            cam_from_world_list=cam_poses,
            config=opt_config,
            rgbs=rgbs,
            masks=None,
            output_dir=output_dir,
        )
    except RuntimeError as e:
        if "out of memory" in str(e).lower():
            print(f"\nâŒ GPU å†…å­˜ä¸è¶³ï¼")
            print(f"  å°è¯•ä½¿ç”¨ CPU æ¨¡å¼...")
            opt_config.device = "cpu"
            # å°†æ•°æ®ç§»åˆ° CPU
            log_depths_dap = [d.cpu() for d in log_depths_dap]
            depths_dap = [d.cpu() for d in depths_dap]
            rgbs = [r.cpu() for r in rgbs]
            for module in depth_reparam_modules:
                module.to("cpu")
            # é‡æ–°è¿è¡Œ
            depths_opt, report = optimize_multi_view_depth(
                depth_reparam_modules=depth_reparam_modules,
                log_depth_daps=log_depths_dap,
                depth_daps=depths_dap,
                cam_from_world_list=cam_poses,
                config=opt_config,
                rgbs=rgbs,
                masks=None,
                output_dir=output_dir,
            )
        else:
            raise
    
    print(f"\nâœ… ä¼˜åŒ–å®Œæˆ")
    print(f"  è¿­ä»£æ¬¡æ•°: {report['iterations']}")
    print(f"  æœ€ç»ˆèƒ½é‡: {report['final_energy']:.6f}")
    
    # ä¿å­˜æŸå¤±å†å²
    if report.get('history') is not None:
        log_time(f"ğŸ“Š ä¿å­˜æŸå¤±å†å²...")
        history = report['history']
        config_dict = report.get('config', {})
        
        # åˆ›å»ºæŸå¤±å†å²ç›®å½•
        loss_history_dir = project_root / "logs" / "loss_history" / scene_name
        loss_history_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜ä¸º JSONï¼ˆåŒ…å«é…ç½®ä¿¡æ¯ï¼‰
        json_path = loss_history_dir / f"loss_history_{timestamp}.json"
        history_data = {
            'config': config_dict,
            'iterations': report['iterations'],
            'final_energy': report['final_energy'],
            'history': {k: v for k, v in history.items()}
        }
        with open(json_path, 'w') as f:
            json.dump(history_data, f, indent=2)
        log_time(f"  âœ… JSON ä¿å­˜: {json_path}")
        
        # ä¿å­˜ä¸º CSVï¼ˆä¾¿äº Excel/Python åˆ†æï¼‰
        csv_path = loss_history_dir / f"loss_history_{timestamp}.csv"
        num_iterations = len(history['total'])
        with open(csv_path, 'w', newline='') as f:
            writer = csv.writer(f)
            # å†™å…¥è¡¨å¤´
            writer.writerow([
                'iteration',
                'total',
                'p2r_raw', 'depth_raw', 'prior_raw', 'smooth_raw', 'scale_raw',
                'p2r_weighted', 'depth_weighted', 'prior_weighted', 'smooth_weighted', 'scale_weighted'
            ])
            # å†™å…¥æ•°æ®
            for i in range(num_iterations):
                writer.writerow([
                    i + 1,
                    history['total'][i],
                    history['geometry_p2r'][i],
                    history['geometry_depth'][i],
                    history['regularization_prior'][i],
                    history['regularization_smooth'][i],
                    history['regularization_scale'][i],
                    history['weighted_p2r'][i],
                    history['weighted_depth'][i],
                    history['weighted_prior'][i],
                    history['weighted_smooth'][i],
                    history['weighted_scale'][i],
                ])
        log_time(f"  âœ… CSV ä¿å­˜: {csv_path}")
        
        # æ‰“å°æŸå¤±ç»Ÿè®¡
        print(f"\nğŸ“Š æŸå¤±ç»Ÿè®¡:")
        print(f"  æ€»æŸå¤±: åˆå§‹={history['total'][0]:.6f}, æœ€ç»ˆ={history['total'][-1]:.6f}, å˜åŒ–={history['total'][0]-history['total'][-1]:.6f}")
        print(f"  P2RæŸå¤±: åˆå§‹={history['geometry_p2r'][0]:.6f}, æœ€ç»ˆ={history['geometry_p2r'][-1]:.6f}")
        print(f"  å…ˆéªŒæŸå¤±: åˆå§‹={history['regularization_prior'][0]:.6f}, æœ€ç»ˆ={history['regularization_prior'][-1]:.6f}")
        print(f"  åŠ æƒP2R: æœ€ç»ˆ={history['weighted_p2r'][-1]:.6f} (æƒé‡={config_dict.get('lambda_p2r', 'N/A')})")
        print(f"  åŠ æƒå…ˆéªŒ: æœ€ç»ˆ={history['weighted_prior'][-1]:.6f} (æƒé‡={config_dict.get('lambda_prior', 'N/A')})")
    
    # éªŒè¯ç»“æœ
    print(f"\nğŸ” éªŒè¯ä¼˜åŒ–ç»“æœ...")
    is_valid, validation_report = validate_optimized_depths(
        depths=depths_opt,
        depth_daps=[d.cpu().numpy() for d in depths_dap],
        far_threshold=100.0,
    )
    
    print(f"  éªŒè¯ç»“æœ: {'âœ…é€šè¿‡' if is_valid else 'âš ï¸æœªé€šè¿‡'}")
    if not is_valid:
        print(f"  è­¦å‘Š: {validation_report}")
    
    # ä¿å­˜ç»“æœ
    print(f"\nğŸ’¾ ä¿å­˜ç»“æœ...")
    output_depths_dir = project_root / "outputs" / "aligned_depths" / scene_name
    output_depths_dir.mkdir(parents=True, exist_ok=True)
    
    for i, (pano_name, depth_opt) in enumerate(zip(pano_names, depths_opt)):
        output_path = output_depths_dir / f"{pano_name}_aligned.npy"
        save_depth_npy(depth_opt, output_path)
        print(f"  âœ… {pano_name}: {output_path}")
    
    # å¯è§†åŒ–æ·±åº¦å˜åŒ–é‡å¯¹æ¯”
    print(f"\nğŸ“Š ç”Ÿæˆæ·±åº¦å˜åŒ–é‡çƒ­åŠ›å›¾...")
    diff_vis_dir = output_depths_dir / "depth_diff_heatmaps"
    diff_vis_dir.mkdir(parents=True, exist_ok=True)
    
    for i, (pano_name, depth_opt) in enumerate(zip(pano_names, depths_opt)):
        # è·å–ä¼˜åŒ–å‰çš„æ·±åº¦ï¼ˆDAPç¼©æ”¾åçš„ï¼‰
        depth_before = depths_dap[i].cpu().numpy()  # å·²ç»æ˜¯ç¼©æ”¾åçš„
        
        # ç”Ÿæˆä¸‰ç§ç±»å‹çš„å¯¹æ¯”å›¾
        for diff_type in ["log_diff", "absolute", "relative"]:
            heatmap_path = diff_vis_dir / f"{pano_name}_diff_{diff_type}.png"
            try:
                visualize_depth_diff_heatmap(
                    depth_before=depth_before,
                    depth_after=depth_opt,
                    diff_type=diff_type,
                    cmap="RdBu_r",
                    vmax=None,  # è‡ªåŠ¨è®¡ç®—
                    save_path=heatmap_path,
                )
            except Exception as e:
                print(f"  âš ï¸  {pano_name} {diff_type} å¯è§†åŒ–å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
    
    print(f"  âœ… æ·±åº¦å˜åŒ–é‡çƒ­åŠ›å›¾å·²ä¿å­˜åˆ°: {diff_vis_dir}")
    print(f"     åŒ…å«: log_diff, absolute, relative ä¸‰ç§å¯¹æ¯”æ–¹å¼")
    
    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼")
    print(f"  ä¼˜åŒ–æ·±åº¦ç›®å½•: {output_depths_dir}")
    print(f"  å˜åŒ–é‡çƒ­åŠ›å›¾: {diff_vis_dir}")


if __name__ == "__main__":
    main()
